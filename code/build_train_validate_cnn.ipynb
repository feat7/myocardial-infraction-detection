{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input,Flatten, Convolution1D, Convolution2D,BatchNormalization,Dense,Input,Dropout,MaxPool1D,GlobalAvgPool1D,\\\n",
    "AveragePooling1D,concatenate,Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_scores(prob,y_true,verbose=1):\n",
    "    y_pred=[]\n",
    "    for pb in prob:\n",
    "        if np.argmax(pb)==0:\n",
    "            y_pred.append(np.array([1,0]))\n",
    "        if np.argmax(pb)==1:\n",
    "            y_pred.append(np.array([0,1]))\n",
    "    y_pred=np.array(y_pred)\n",
    "    \n",
    "    accuracy=np.sum(y_pred[:,0]==y_true[:,0])/y_true.shape[0]\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for y_p,y_t in zip(y_pred,y_true): \n",
    "        if y_p[1]==1 and y_t[1]==1:\n",
    "            tp=tp+1\n",
    "        if y_p[1]==1 and y_t[1]==0:\n",
    "            fp=fp+1\n",
    "        if y_p[1]==0 and y_t[1]==0:\n",
    "            tn=tn+1\n",
    "        if y_p[1]==0 and y_t[1]==1:\n",
    "            fn=fn+1\n",
    "    if (tp+fn)==0:\n",
    "        sensitivity='nan'\n",
    "    else:\n",
    "        sensitivity=tp/(tp+fn)\n",
    "    if (tn+fp)==0:    \n",
    "        specificity='nan'\n",
    "    else:\n",
    "        specificity=tn/(tn+fp)\n",
    "    scores={'accuracy':accuracy,'sensitivity':sensitivity,'specificity':specificity}\n",
    "    if verbose:\n",
    "        print('accuracy: {}\\t sensitivity: {}\\t specificity: {}'.format\\\n",
    "              (accuracy,sensitivity,specificity))\n",
    "    return scores\n",
    "\n",
    "def get_patient_data(ind_train,ind_test,patients):\n",
    "    patients=np.array(patients)\n",
    "    patient_train=patients[ind_train]\n",
    "    patient_test=patients[ind_test]\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    X_train1=[]\n",
    "    X_test1=[]\n",
    "    X_train2=[]\n",
    "    X_test2=[]\n",
    "    X_train3=[]\n",
    "    X_test3=[]\n",
    "    \n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "    for patient in patient_train:\n",
    "        patient_keys=[key for key in data_dict.keys() if patient in key]\n",
    "        for key in patient_keys:\n",
    "            segments,label_bin=data_dict[key]\n",
    "            X_train1=X_train1+list(np.reshape(segments[:,0,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_train2=X_train2+list(np.reshape(segments[:,1,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_train3=X_train3+list(np.reshape(segments[:,2,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            y_train=y_train+list(np.tile(label_bin,[segments.shape[0],1]))\n",
    "            \n",
    "                     \n",
    "    X_train1=np.array(X_train1)    \n",
    "    X_train2=np.array(X_train2)    \n",
    "    X_train3=np.array(X_train3)    \n",
    "    y_train=np.array(y_train)    \n",
    "    \n",
    "    for patient in patient_test:\n",
    "        patient_keys=[key for key in data_dict.keys() if patient in key]\n",
    "        for key in patient_keys:\n",
    "            segments,label_bin=data_dict[key]\n",
    "            X_test1=X_test1+list(np.reshape(segments[:,0,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_test2=X_test2+list(np.reshape(segments[:,1,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_test3=X_test3+list(np.reshape(segments[:,2,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            y_test=y_test+list(np.tile(label_bin,[segments.shape[0],1]))\n",
    "    X_test1=np.array(X_test1)    \n",
    "    X_test2=np.array(X_test2)    \n",
    "    X_test3=np.array(X_test3)    \n",
    "    y_test=np.array(y_test)    \n",
    "    \n",
    "    X_train=[X_train1,X_train2,X_train3]\n",
    "    X_test=[X_test1,X_test2,X_test3]\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ECG samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict=pickle.load(open(os.path.join('..','data','imi_hc_64Hz_3_lead.bin'),'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split based on patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients=np.array(list(set([ key.split('/')[-2] for key in list(data_dict.keys())])))\n",
    "kfold_patient= KFold(n_splits=len(patients),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 196, 4)       16          input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 196, 4)       24          input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 196, 4)       32          input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 196, 4)       40          input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 196, 4)       68          input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 196, 4)       132         input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 196, 4)       260         input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 196, 4)       16          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 196, 4)       24          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 196, 4)       32          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 196, 4)       40          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 196, 4)       68          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 196, 4)       132         input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 196, 4)       260         input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 196, 4)       16          input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 196, 4)       24          input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, 196, 4)       32          input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, 196, 4)       40          input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, 196, 4)       68          input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)             (None, 196, 4)       132         input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)             (None, 196, 4)       260         input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 196, 4)       16          conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 196, 4)       16          conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 196, 4)       16          conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 196, 4)       16          conv1d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 196, 4)       16          conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 196, 4)       16          conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 196, 4)       16          conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 196, 4)       16          conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 196, 4)       16          conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 196, 4)       16          conv1d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 196, 4)       16          conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 196, 4)       16          conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 196, 4)       16          conv1d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 196, 4)       16          conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 196, 4)       16          conv1d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 196, 4)       16          conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 196, 4)       16          conv1d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 196, 4)       16          conv1d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 196, 4)       16          conv1d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 196, 4)       16          conv1d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 196, 4)       16          conv1d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 196, 4)       0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 196, 4)       0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 196, 4)       0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 196, 4)       0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 196, 4)       0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 196, 4)       0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 196, 4)       0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 196, 4)       0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 196, 4)       0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 196, 4)       0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 196, 4)       0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 196, 4)       0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 196, 4)       0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 196, 4)       0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 196, 4)       0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 196, 4)       0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 196, 4)       0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 196, 4)       0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 196, 4)       0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 196, 4)       0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 196, 4)       0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling1D) (None, 98, 4)        0           activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling1D) (None, 98, 4)        0           activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling1D) (None, 98, 4)        0           activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling1D) (None, 98, 4)        0           activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling1D) (None, 98, 4)        0           activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling1D) (None, 98, 4)        0           activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling1D) (None, 98, 4)        0           activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling1D) (None, 98, 4)        0           activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling1D) (None, 98, 4)        0           activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling1D) (None, 98, 4)        0           activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling1D) (None, 98, 4)        0           activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling1D) (None, 98, 4)        0           activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling1D) (None, 98, 4)        0           activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling1D) (None, 98, 4)        0           activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_107 (MaxPooling1D (None, 98, 4)        0           activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_108 (MaxPooling1D (None, 98, 4)        0           activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_109 (MaxPooling1D (None, 98, 4)        0           activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_110 (MaxPooling1D (None, 98, 4)        0           activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_111 (MaxPooling1D (None, 98, 4)        0           activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_112 (MaxPooling1D (None, 98, 4)        0           activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_113 (MaxPooling1D (None, 98, 4)        0           activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 98, 28)       0           max_pooling1d_86[0][0]           \n",
      "                                                                 max_pooling1d_87[0][0]           \n",
      "                                                                 max_pooling1d_88[0][0]           \n",
      "                                                                 max_pooling1d_89[0][0]           \n",
      "                                                                 max_pooling1d_90[0][0]           \n",
      "                                                                 max_pooling1d_91[0][0]           \n",
      "                                                                 max_pooling1d_92[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 98, 28)       0           max_pooling1d_93[0][0]           \n",
      "                                                                 max_pooling1d_94[0][0]           \n",
      "                                                                 max_pooling1d_95[0][0]           \n",
      "                                                                 max_pooling1d_96[0][0]           \n",
      "                                                                 max_pooling1d_97[0][0]           \n",
      "                                                                 max_pooling1d_98[0][0]           \n",
      "                                                                 max_pooling1d_99[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 98, 28)       0           max_pooling1d_107[0][0]          \n",
      "                                                                 max_pooling1d_108[0][0]          \n",
      "                                                                 max_pooling1d_109[0][0]          \n",
      "                                                                 max_pooling1d_110[0][0]          \n",
      "                                                                 max_pooling1d_111[0][0]          \n",
      "                                                                 max_pooling1d_112[0][0]          \n",
      "                                                                 max_pooling1d_113[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 98, 84)       0           concatenate_40[0][0]             \n",
      "                                                                 concatenate_41[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 84)           0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 2)            170         global_average_pooling1d_7[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,222\n",
      "Trainable params: 2,054\n",
      "Non-trainable params: 168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_bn(filters,kernel_size,input_layer):\n",
    "    x=Convolution1D(filters=filters,kernel_size=kernel_size,padding='same',\n",
    "                    kernel_regularizer=None)(input_layer) \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPool1D(pool_size=2)(x)\n",
    "    return x\n",
    "\n",
    "def inception_block(input_layer):\n",
    "    conv3=conv_bn(4,3,input_layer)\n",
    "    conv5=conv_bn(4,5,input_layer)\n",
    "    conv7=conv_bn(4,7,input_layer)\n",
    "    conv9=conv_bn(4,9,input_layer)\n",
    "    conv16=conv_bn(4,16,input_layer)  \n",
    "    conv32=conv_bn(4,32,input_layer)\n",
    "    conv64=conv_bn(4,64,input_layer)\n",
    "    return concatenate([conv3,conv5,conv7,conv9,conv16,conv32,conv64])\n",
    "\n",
    "def get_model(input_shape):\n",
    "    input_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_bloinput_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_block(input_layer2)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    x=concatenate([block1_ch1,block1_ch2,block1_ch3])\n",
    "    x=GlobalAvgPool1D()(x)\n",
    "    output_layer=Dense(2,activation='softmax',kernel_regularizer=L1L2(l1=0.0,l2=0.001))(x)\n",
    "    \n",
    "    model_paper=Model(inputs=[input_layer1,input_layer2,input_layer3],outputs=output_layer)\n",
    "    model_paper.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    return model_paper\n",
    "model=get_model([196,1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_62 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_65 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_67 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 196, 196)     392         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 196, 98)      196         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 196, 49)      98          input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 196, 20)      40          input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 196, 196)     392         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 196, 98)      196         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 196, 49)      98          input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 196, 20)      40          input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 196, 196)     392         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 196, 98)      196         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 196, 49)      98          input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 196, 20)      40          input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 196, 196)     784         dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 196, 98)      392         dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 196, 49)      196         dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 196, 20)      80          dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 196, 196)     784         dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 196, 98)      392         dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 196, 49)      196         dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 196, 20)      80          dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 196, 196)     784         dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 196, 98)      392         dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 196, 49)      196         dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 196, 20)      80          dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 196, 196)     0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 196, 98)      0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 196, 49)      0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 196, 20)      0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 196, 196)     0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 196, 98)      0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 196, 49)      0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 196, 20)      0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 196, 196)     0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 196, 98)      0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 196, 49)      0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 196, 20)      0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 196, 363)     0           activation_192[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 196, 363)     0           activation_197[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 196, 363)     0           activation_207[0][0]             \n",
      "                                                                 activation_208[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 196, 1089)    0           concatenate_46[0][0]             \n",
      "                                                                 concatenate_47[0][0]             \n",
      "                                                                 concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 1089)         0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 2)            2180        global_average_pooling1d_8[0][0] \n",
      "==================================================================================================\n",
      "Total params: 8,714\n",
      "Trainable params: 6,536\n",
      "Non-trainable params: 2,178\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "def dense_bn(units, input_layer):\n",
    "    x=Dense(units)(input_layer) \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def inception_block(input_layer):\n",
    "    dense1=dense_bn(196, input_layer)\n",
    "    dense2=dense_bn(98, input_layer)  \n",
    "    dense3=dense_bn(49, input_layer)  \n",
    "    dense4=dense_bn(20, input_layer)\n",
    "    dense5=dense_bn(10, input_layer)\n",
    "    return concatenate([dense1, dense2, dense3, dense4])\n",
    "\n",
    "def ann_model(input_shape):\n",
    "    input_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_bloinput_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_block(input_layer2)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    x=concatenate([block1_ch1,block1_ch2,block1_ch3])\n",
    "    x=GlobalAvgPool1D()(x)\n",
    "    output_layer=Dense(2,activation='softmax',kernel_regularizer=L1L2(l1=0.0,l2=0.001))(x)\n",
    "    \n",
    "    model_paper=Model(inputs=[input_layer1,input_layer2,input_layer3],outputs=output_layer)\n",
    "    model_paper.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    return model_paper\n",
    "model=get_model([196,1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1/82\n",
      "(6092, 196, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6092 samples, validate on 185 samples\n",
      "Epoch 1/200\n",
      "6092/6092 [==============================] - 55s 9ms/step - loss: 0.4419 - acc: 0.7841 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 2/200\n",
      "6092/6092 [==============================] - 46s 8ms/step - loss: 0.3928 - acc: 0.8157 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 3/200\n",
      "6092/6092 [==============================] - 46s 8ms/step - loss: 0.3893 - acc: 0.8145 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 4/200\n",
      "6092/6092 [==============================] - 46s 8ms/step - loss: 0.3914 - acc: 0.8157 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 5/200\n",
      "3040/6092 [=============>................] - ETA: 22s - loss: 0.3850 - acc: 0.8201"
     ]
    }
   ],
   "source": [
    "cvscores=[]\n",
    "i=0\n",
    "for ind_train,ind_test in kfold_patient.split(X=patients,y=[0]*len(patients)): \n",
    "    i=i+1    \n",
    "    print('fold: {}/{}'.format(i,kfold_patient.n_splits))\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=get_patient_data(ind_train,ind_test,patients)\n",
    "#     model = ann_model(X_train[0].shape[1:])\n",
    "\n",
    "    print((X_train[0].shape))\n",
    "    model_paper=ann_model(X_train[0].shape[1:])\n",
    "    K.set_value(model_paper.optimizer.lr,1e-3)\n",
    "    \n",
    "    model_paper.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=200,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_test,y_test),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='loss',min_delta=0.0,patience=10,verbose=1),\n",
    "            ReduceLROnPlateau(min_lr=1e-5,factor=.1,monitor='loss',epsilon=0.0001,patience=5,verbose=1,),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prob = model_paper.predict(X_test)\n",
    "    scores=calculate_scores(prob,y_test)\n",
    "    cvscores.append(scores)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cvscores=[]\n",
    "i=0\n",
    "for ind_train,ind_test in kfold_patient.split(X=patients,y=[0]*len(patients)): \n",
    "    i=i+1    \n",
    "    print('fold: {}/{}'.format(i,kfold_patient.n_splits))\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=get_patient_data(ind_train,ind_test,patients)\n",
    "\n",
    "    model_paper=get_model(X_train[0].shape[1:])\n",
    "    K.set_value(model_paper.optimizer.lr,1e-3)\n",
    "    \n",
    "    model_paper.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=200,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_test,y_test),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='loss',min_delta=0.0,patience=10,verbose=1),\n",
    "            ReduceLROnPlateau(min_lr=1e-5,factor=.1,monitor='loss',epsilon=0.0001,patience=5,verbose=1,),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prob = model_paper.predict(X_test)\n",
    "    scores=calculate_scores(prob,y_test)\n",
    "    cvscores.append(scores)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Average Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensitivity=[]\n",
    "specificity=[]\n",
    "accuracy=[]\n",
    "\n",
    "for score in cvscores:\n",
    "    if score['sensitivity']!='nan':\n",
    "        sensitivity.append(score['sensitivity'])\n",
    "    if score['specificity']!='nan':\n",
    "        specificity.append(score['specificity'])\n",
    "    accuracy.append(score['accuracy'])\n",
    "\n",
    "np.mean(np.array(accuracy)),np.mean(np.array(sensitivity)),np.mean(np.array(specificity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
