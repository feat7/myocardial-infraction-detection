{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input,Flatten, Convolution1D, Convolution2D,BatchNormalization,Dense,Input,Dropout,MaxPool1D,GlobalAvgPool1D,\\\n",
    "AveragePooling1D,concatenate,Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_scores(prob,y_true,verbose=1):\n",
    "    y_pred=[]\n",
    "    for pb in prob:\n",
    "        if np.argmax(pb)==0:\n",
    "            y_pred.append(np.array([1,0]))\n",
    "        if np.argmax(pb)==1:\n",
    "            y_pred.append(np.array([0,1]))\n",
    "    y_pred=np.array(y_pred)\n",
    "    \n",
    "    accuracy=np.sum(y_pred[:,0]==y_true[:,0])/y_true.shape[0]\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for y_p,y_t in zip(y_pred,y_true): \n",
    "        if y_p[1]==1 and y_t[1]==1:\n",
    "            tp=tp+1\n",
    "        if y_p[1]==1 and y_t[1]==0:\n",
    "            fp=fp+1\n",
    "        if y_p[1]==0 and y_t[1]==0:\n",
    "            tn=tn+1\n",
    "        if y_p[1]==0 and y_t[1]==1:\n",
    "            fn=fn+1\n",
    "    if (tp+fn)==0:\n",
    "        sensitivity='nan'\n",
    "    else:\n",
    "        sensitivity=tp/(tp+fn)\n",
    "    if (tn+fp)==0:    \n",
    "        specificity='nan'\n",
    "    else:\n",
    "        specificity=tn/(tn+fp)\n",
    "    scores={'accuracy':accuracy,'sensitivity':sensitivity,'specificity':specificity}\n",
    "    if verbose:\n",
    "        print('accuracy: {}\\t sensitivity: {}\\t specificity: {}'.format\\\n",
    "              (accuracy,sensitivity,specificity))\n",
    "    return scores\n",
    "\n",
    "def get_patient_data(ind_train,ind_test,patients):\n",
    "    patients=np.array(patients)\n",
    "    patient_train=patients[ind_train]\n",
    "    patient_test=patients[ind_test]\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    X_train1=[]\n",
    "    X_test1=[]\n",
    "    X_train2=[]\n",
    "    X_test2=[]\n",
    "    X_train3=[]\n",
    "    X_test3=[]\n",
    "    \n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "    for patient in patient_train:\n",
    "        patient_keys=[key for key in data_dict.keys() if patient in key]\n",
    "        for key in patient_keys:\n",
    "            segments,label_bin=data_dict[key]\n",
    "            X_train1=X_train1+list(np.reshape(segments[:,0,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_train2=X_train2+list(np.reshape(segments[:,1,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_train3=X_train3+list(np.reshape(segments[:,2,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            y_train=y_train+list(np.tile(label_bin,[segments.shape[0],1]))\n",
    "            \n",
    "                     \n",
    "    X_train1=np.array(X_train1)    \n",
    "    X_train2=np.array(X_train2)    \n",
    "    X_train3=np.array(X_train3)    \n",
    "    y_train=np.array(y_train)    \n",
    "    \n",
    "    for patient in patient_test:\n",
    "        patient_keys=[key for key in data_dict.keys() if patient in key]\n",
    "        for key in patient_keys:\n",
    "            segments,label_bin=data_dict[key]\n",
    "            X_test1=X_test1+list(np.reshape(segments[:,0,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_test2=X_test2+list(np.reshape(segments[:,1,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_test3=X_test3+list(np.reshape(segments[:,2,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            y_test=y_test+list(np.tile(label_bin,[segments.shape[0],1]))\n",
    "    X_test1=np.array(X_test1)    \n",
    "    X_test2=np.array(X_test2)    \n",
    "    X_test3=np.array(X_test3)    \n",
    "    y_test=np.array(y_test)    \n",
    "    \n",
    "    X_train=[X_train1,X_train2,X_train3]\n",
    "    X_test=[X_test1,X_test2,X_test3]\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ECG samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict=pickle.load(open(os.path.join('..','data','imi_hc_64Hz_3_lead.bin'),'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split based on patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients=np.array(list(set([ key.split('/')[-2] for key in list(data_dict.keys())])))\n",
    "kfold_patient= KFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 196, 4)       132         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 196, 4)       260         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 196, 4)       132         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 196, 4)       260         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 196, 4)       132         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 196, 4)       260         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 196, 4)       16          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 196, 4)       16          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 196, 4)       16          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 196, 4)       16          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 196, 4)       16          conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 196, 4)       16          conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 196, 4)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 196, 4)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 196, 4)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 196, 4)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 196, 4)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 196, 4)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 98, 4)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 98, 4)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 98, 4)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 98, 4)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 98, 4)        0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 98, 4)        0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 98, 8)        0           max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 98, 8)        0           max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 98, 8)        0           max_pooling1d_9[0][0]            \n",
      "                                                                 max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 98, 24)       0           concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 24)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            50          global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,322\n",
      "Trainable params: 1,274\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_bn(filters,kernel_size,input_layer):\n",
    "    x=Convolution1D(filters=filters,kernel_size=kernel_size,padding='same',\n",
    "                    kernel_regularizer=None)(input_layer) \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPool1D(pool_size=2)(x)\n",
    "    return x\n",
    "\n",
    "def inception_block(input_layer):\n",
    "#     conv3=conv_bn(4,3,input_layer)\n",
    "#     conv5=conv_bn(4,5,input_layer)\n",
    "#     conv7=conv_bn(4,7,input_layer)\n",
    "#     conv9=conv_bn(4,9,input_layer)\n",
    "#     conv16=conv_bn(4,16,input_layer)  \n",
    "    conv32=conv_bn(4,32,input_layer)\n",
    "    conv64=conv_bn(4,64,input_layer)\n",
    "    return concatenate([conv32,conv64])\n",
    "\n",
    "def get_model(input_shape):\n",
    "    input_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_bloinput_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_block(input_layer2)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    x=concatenate([block1_ch1,block1_ch2,block1_ch3])\n",
    "    x=GlobalAvgPool1D()(x)\n",
    "    output_layer=Dense(2,activation='softmax',kernel_regularizer=L1L2(l1=0.0,l2=0.001))(x)\n",
    "    \n",
    "    model_paper=Model(inputs=[input_layer1,input_layer2,input_layer3],outputs=output_layer)\n",
    "    model_paper.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    return model_paper\n",
    "model=get_model([196,1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_62 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_65 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_67 (InputLayer)           (None, 196, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 196, 196)     392         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 196, 98)      196         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 196, 49)      98          input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 196, 20)      40          input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 196, 196)     392         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 196, 98)      196         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 196, 49)      98          input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 196, 20)      40          input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 196, 196)     392         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 196, 98)      196         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 196, 49)      98          input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 196, 20)      40          input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 196, 196)     784         dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 196, 98)      392         dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 196, 49)      196         dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 196, 20)      80          dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 196, 196)     784         dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 196, 98)      392         dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 196, 49)      196         dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 196, 20)      80          dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 196, 196)     784         dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 196, 98)      392         dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 196, 49)      196         dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 196, 20)      80          dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 196, 196)     0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 196, 98)      0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 196, 49)      0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 196, 20)      0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 196, 196)     0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 196, 98)      0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 196, 49)      0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 196, 20)      0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 196, 196)     0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 196, 98)      0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 196, 49)      0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 196, 20)      0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 196, 363)     0           activation_192[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 196, 363)     0           activation_197[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 196, 363)     0           activation_207[0][0]             \n",
      "                                                                 activation_208[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 196, 1089)    0           concatenate_46[0][0]             \n",
      "                                                                 concatenate_47[0][0]             \n",
      "                                                                 concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 1089)         0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 2)            2180        global_average_pooling1d_8[0][0] \n",
      "==================================================================================================\n",
      "Total params: 8,714\n",
      "Trainable params: 6,536\n",
      "Non-trainable params: 2,178\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "def dense_bn(units, input_layer):\n",
    "    x=Dense(units)(input_layer) \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def inception_block(input_layer):\n",
    "    dense1=dense_bn(196, input_layer)\n",
    "    dense2=dense_bn(98, input_layer)  \n",
    "    dense3=dense_bn(49, input_layer)  \n",
    "    dense4=dense_bn(20, input_layer)\n",
    "    dense5=dense_bn(10, input_layer)\n",
    "    return concatenate([dense1, dense2, dense3, dense4])\n",
    "\n",
    "def ann_model(input_shape):\n",
    "    input_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_bloinput_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_block(input_layer2)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    x=concatenate([block1_ch1,block1_ch2,block1_ch3])\n",
    "    x=GlobalAvgPool1D()(x)\n",
    "    output_layer=Dense(2,activation='softmax',kernel_regularizer=L1L2(l1=0.0,l2=0.001))(x)\n",
    "    \n",
    "    model_paper=Model(inputs=[input_layer1,input_layer2,input_layer3],outputs=output_layer)\n",
    "    model_paper.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    return model_paper\n",
    "model=get_model([196,1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1/10\n",
      "(5737, 196, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ann_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-af1f61d7cfaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel_paper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mann_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_paper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ann_model' is not defined"
     ]
    }
   ],
   "source": [
    "cvscores=[]\n",
    "i=0\n",
    "for ind_train,ind_test in kfold_patient.split(X=patients,y=[0]*len(patients)): \n",
    "    i=i+1    \n",
    "    print('fold: {}/{}'.format(i,kfold_patient.n_splits))\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=get_patient_data(ind_train,ind_test,patients)\n",
    "#     model = ann_model(X_train[0].shape[1:])\n",
    "\n",
    "    print((X_train[0].shape))\n",
    "    model_paper=ann_model(X_train[0].shape[1:])\n",
    "    K.set_value(model_paper.optimizer.lr,1e-3)\n",
    "    \n",
    "    model_paper.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=200,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_test,y_test),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='loss',min_delta=0.0,patience=10,verbose=1),\n",
    "            ReduceLROnPlateau(min_lr=1e-5,factor=.1,monitor='loss',epsilon=0.0001,patience=5,verbose=1,),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prob = model_paper.predict(X_test)\n",
    "    scores=calculate_scores(prob,y_test)\n",
    "    cvscores.append(scores)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5482 samples, validate on 795 samples\n",
      "Epoch 1/200\n",
      "5482/5482 [==============================] - 7s 1ms/step - loss: 0.4395 - acc: 0.7955 - val_loss: 0.6426 - val_acc: 0.6151\n",
      "Epoch 2/200\n",
      "5482/5482 [==============================] - 4s 731us/step - loss: 0.3881 - acc: 0.8265 - val_loss: 0.5750 - val_acc: 0.6516\n",
      "Epoch 3/200\n",
      "5482/5482 [==============================] - 4s 750us/step - loss: 0.3588 - acc: 0.8417 - val_loss: 0.5431 - val_acc: 0.6579\n",
      "Epoch 4/200\n",
      "5482/5482 [==============================] - 4s 776us/step - loss: 0.3353 - acc: 0.8561 - val_loss: 0.5178 - val_acc: 0.6629\n",
      "Epoch 5/200\n",
      "5482/5482 [==============================] - 4s 804us/step - loss: 0.3161 - acc: 0.8698 - val_loss: 0.5046 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "5482/5482 [==============================] - 4s 732us/step - loss: 0.3086 - acc: 0.8736 - val_loss: 0.4727 - val_acc: 0.6730\n",
      "Epoch 7/200\n",
      "5482/5482 [==============================] - 4s 745us/step - loss: 0.2919 - acc: 0.8794 - val_loss: 0.4523 - val_acc: 0.6843\n",
      "Epoch 8/200\n",
      "5482/5482 [==============================] - 4s 772us/step - loss: 0.2830 - acc: 0.8851 - val_loss: 0.4249 - val_acc: 0.7057\n",
      "Epoch 9/200\n",
      "5482/5482 [==============================] - 4s 746us/step - loss: 0.2736 - acc: 0.8909 - val_loss: 0.4393 - val_acc: 0.7522\n",
      "Epoch 10/200\n",
      "5482/5482 [==============================] - 4s 765us/step - loss: 0.2634 - acc: 0.8929 - val_loss: 0.4182 - val_acc: 0.7031\n",
      "Epoch 11/200\n",
      "5482/5482 [==============================] - 4s 746us/step - loss: 0.2570 - acc: 0.9031 - val_loss: 0.4140 - val_acc: 0.7258\n",
      "Epoch 12/200\n",
      "5482/5482 [==============================] - 4s 767us/step - loss: 0.2503 - acc: 0.9035 - val_loss: 0.4046 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "5482/5482 [==============================] - 4s 785us/step - loss: 0.2442 - acc: 0.9092 - val_loss: 0.4206 - val_acc: 0.7535\n",
      "Epoch 14/200\n",
      "5482/5482 [==============================] - 4s 749us/step - loss: 0.2405 - acc: 0.9104 - val_loss: 0.3947 - val_acc: 0.7384\n",
      "Epoch 15/200\n",
      "5482/5482 [==============================] - 4s 763us/step - loss: 0.2369 - acc: 0.9106 - val_loss: 0.4074 - val_acc: 0.7799\n",
      "Epoch 16/200\n",
      "5482/5482 [==============================] - 4s 746us/step - loss: 0.2303 - acc: 0.9157 - val_loss: 0.3911 - val_acc: 0.7459\n",
      "Epoch 17/200\n",
      "5482/5482 [==============================] - 4s 752us/step - loss: 0.2271 - acc: 0.9188 - val_loss: 0.4141 - val_acc: 0.8013\n",
      "Epoch 18/200\n",
      "5482/5482 [==============================] - 4s 768us/step - loss: 0.2166 - acc: 0.9228 - val_loss: 0.3800 - val_acc: 0.8239\n",
      "Epoch 19/200\n",
      "5482/5482 [==============================] - 4s 757us/step - loss: 0.2161 - acc: 0.9225 - val_loss: 0.3985 - val_acc: 0.7447\n",
      "Epoch 20/200\n",
      "5482/5482 [==============================] - 5s 822us/step - loss: 0.2172 - acc: 0.9230 - val_loss: 0.3881 - val_acc: 0.7660\n",
      "Epoch 21/200\n",
      "5482/5482 [==============================] - 4s 752us/step - loss: 0.2167 - acc: 0.9263 - val_loss: 0.4093 - val_acc: 0.7346\n",
      "Epoch 22/200\n",
      "5482/5482 [==============================] - 4s 757us/step - loss: 0.2074 - acc: 0.9281 - val_loss: 0.4052 - val_acc: 0.8101\n",
      "Epoch 23/200\n",
      "5482/5482 [==============================] - 4s 771us/step - loss: 0.2035 - acc: 0.9305 - val_loss: 0.4014 - val_acc: 0.7472\n",
      "Epoch 24/200\n",
      "5482/5482 [==============================] - 4s 755us/step - loss: 0.2022 - acc: 0.9318 - val_loss: 0.3655 - val_acc: 0.8377\n",
      "Epoch 25/200\n",
      "5482/5482 [==============================] - 4s 786us/step - loss: 0.1985 - acc: 0.9369 - val_loss: 0.3856 - val_acc: 0.7522\n",
      "Epoch 26/200\n",
      "4768/5482 [=========================>....] - ETA: 0s - loss: 0.1919 - acc: 0.9369"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0d26c1014c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         callbacks=[\n\u001b[1;32m     21\u001b[0m             \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         ]\n\u001b[1;32m     24\u001b[0m     )\n",
      "\u001b[0;32m/home/vinay/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/vinay/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinay/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinay/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vinay/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cvscores=[]\n",
    "i=0\n",
    "for ind_train,ind_test in kfold_patient.split(X=patients,y=[0]*len(patients)): \n",
    "    i=i+1    \n",
    "    print('fold: {}/{}'.format(i,kfold_patient.n_splits))\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=get_patient_data(ind_train,ind_test,patients)\n",
    "\n",
    "    model_paper=get_model(X_train[0].shape[1:])\n",
    "    K.set_value(model_paper.optimizer.lr,1e-3)\n",
    "    \n",
    "    model_paper.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=200,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_test,y_test),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='loss',min_delta=0.0,patience=10,verbose=1),\n",
    "            ReduceLROnPlateau(min_lr=1e-5,factor=.1,monitor='loss',epsilon=0.0001,patience=5,verbose=1,),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prob = model_paper.predict(X_test)\n",
    "    scores=calculate_scores(prob,y_test)\n",
    "    cvscores.append(scores)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Average Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensitivity=[]\n",
    "specificity=[]\n",
    "accuracy=[]\n",
    "\n",
    "for score in cvscores:\n",
    "    if score['sensitivity']!='nan':\n",
    "        sensitivity.append(score['sensitivity'])\n",
    "    if score['specificity']!='nan':\n",
    "        specificity.append(score['specificity'])\n",
    "    accuracy.append(score['accuracy'])\n",
    "\n",
    "np.mean(np.array(accuracy)),np.mean(np.array(sensitivity)),np.mean(np.array(specificity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
